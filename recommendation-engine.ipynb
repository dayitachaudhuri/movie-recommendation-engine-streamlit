{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMMENDATION ENGINE:\n",
    "\n",
    "### Notebook Contents:\n",
    "\n",
    "- Content-Based Filtering using TMDB 5000 Dataset\n",
    "    \n",
    "- Collaborative Filtering using MovieLens Dataset\n",
    "    \n",
    "- Evaluation\n",
    "    \n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pymongo import MongoClient\\nclient = MongoClient()\\ndb1 = client.moviesdatabase\\nmovies = pd.DataFrame(list(db1.tmdb5000.find()))\\ndb2 = client.creditsdatabase\\ncredits = pd.DataFrame(list(db2.tmdb5000.find()))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies=pd.read_csv('dataset/tmdb_5000_movies.csv')\n",
    "credits=pd.read_csv('dataset/tmdb_5000_credits.csv')\n",
    "\n",
    "'''\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db1 = client.moviesdatabase\n",
    "movies = pd.DataFrame(list(db1.tmdb5000.find()))\n",
    "db2 = client.creditsdatabase\n",
    "credits = pd.DataFrame(list(db2.tmdb5000.find()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=movies.merge(credits, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=movies[['id','title','overview','genres','keywords','cast','crew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(obj):\n",
    "    L=[]\n",
    "    for i in ast.literal_eval(obj):\n",
    "        L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "movies['genres']=movies['genres'].apply(convert)\n",
    "movies['keywords']=movies['keywords'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2(obj):\n",
    "    L=[]\n",
    "    count=0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if count!=3:\n",
    "            L.append(i['name'])\n",
    "            count+=1\n",
    "        else:\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['cast']=movies['cast'].apply(convert2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert3(obj):\n",
    "    L=[]\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job']=='Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['crew']=movies['crew'].apply(convert3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords']=movies['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['cast']=movies['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['crew']=movies['crew'].apply(lambda x: [i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview']=movies['overview'].apply(lambda x: str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20172\\929390074.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(lambda x: \" \".join(x))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20172\\929390074.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "movies['tags']=movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']\n",
    "new_df=movies[['id','title','tags']]\n",
    "new_df['tags']=new_df['tags'].apply(lambda x: \" \".join(x))\n",
    "new_df['tags']=new_df['tags'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20172\\3117893756.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags']=new_df['tags'].apply(stem)\n"
     ]
    }
   ],
   "source": [
    "def stem(text):\n",
    "    y=[]\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "new_df['tags']=new_df['tags'].apply(stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors=cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1216, 0.29986532511593345),\n",
       " (2409, 0.28644594961577313),\n",
       " (507, 0.2710098294963041),\n",
       " (539, 0.2706659809803833),\n",
       " (1204, 0.2625754538144587)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity=cosine_similarity(vectors)\n",
    "sorted(list(enumerate(similarity[0])), reverse=True, key=lambda x:x[1])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index=(new_df[new_df['title']==movie].index[0])\n",
    "    distances=similarity[movie_index]\n",
    "    movies_list=sorted(list(enumerate(distances)), reverse=True, key=lambda x:x[1])[1:6]\n",
    "\n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(new_df.to_dict(),open('movies_dict.pkl','wb'))\n",
    "pickle.dump(similarity,open('recommend_1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(ratings, test_size = 0.30, random_state = 42)\n",
    "\n",
    "user_data = X_train.pivot(index = 'userId', columns = 'movieId', values = 'rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of train and test datasets\n",
    "dummy_train = X_train.copy()\n",
    "dummy_test = X_test.copy()\n",
    "\n",
    "dummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x > 0 else 1)\n",
    "dummy_test['rating'] = dummy_test['rating'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The movies not rated by user is marked as 1 for prediction \n",
    "dummy_train = dummy_train.pivot(index = 'userId', columns = 'movieId', values = 'rating').fillna(1)\n",
    "\n",
    "# The movies not rated by user is marked as 0 for evaluation \n",
    "dummy_test = dummy_test.pivot(index ='userId', columns = 'movieId', values = 'rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# User Similarity Matrix using Cosine similarity as a similarity measure between Users\n",
    "user_similarity = cosine_similarity(user_data)\n",
    "user_similarity[np.isnan(user_similarity)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_ratings = np.dot(user_similarity, user_data)\n",
    "user_final_ratings = np.multiply(user_predicted_ratings, dummy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_similarity,open('recommend_2.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
